{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('sonar_dataset.csv',header=None)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "75   0.0202  0.0104  0.0325  0.0239  0.0807  0.1529  0.1154  0.0608  0.1317   \n",
       "64   0.0071  0.0103  0.0135  0.0494  0.0253  0.0806  0.0701  0.0738  0.0117   \n",
       "202  0.0272  0.0378  0.0488  0.0848  0.1127  0.1103  0.1349  0.2337  0.3113   \n",
       "8    0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "81   0.0100  0.0194  0.0155  0.0489  0.0839  0.1009  0.1627  0.2071  0.2696   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "75   0.1370  ...  0.0127  0.0081  0.0067  0.0043  0.0065  0.0049  0.0054   \n",
       "64   0.0898  ...  0.0043  0.0048  0.0076  0.0124  0.0105  0.0054  0.0032   \n",
       "202  0.3997  ...  0.0091  0.0045  0.0043  0.0043  0.0098  0.0054  0.0051   \n",
       "8    0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "81   0.2990  ...  0.0130  0.0073  0.0077  0.0075  0.0060  0.0080  0.0019   \n",
       "\n",
       "         58      59  60  \n",
       "75   0.0073  0.0054   R  \n",
       "64   0.0073  0.0063   R  \n",
       "202  0.0065  0.0103   M  \n",
       "8    0.0059  0.0022   R  \n",
       "81   0.0053  0.0019   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "       ...   \n",
       "56    float64\n",
       "57    float64\n",
       "58    float64\n",
       "59    float64\n",
       "60     object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109    M\n",
       "138    M\n",
       "198    M\n",
       "75     R\n",
       "133    M\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(60,axis='columns')\n",
    "y=df[60]\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "     df[column].replace({'R': 1,'M': 0},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174    0\n",
       "90     1\n",
       "70     1\n",
       "16     1\n",
       "51     1\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "0    111\n",
       "1     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 60)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 60)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss should be binary_crossentropy since its a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.5605 - loss: 0.6903 \n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.5222 - loss: 0.6819\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.5543 - loss: 0.6670\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.6670 - loss: 0.6418\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7302 - loss: 0.6065\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.7627 - loss: 0.5701\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.7944 - loss: 0.5309\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.7384 - loss: 0.5187\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.8480 - loss: 0.4526\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8139 - loss: 0.4192\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.8103 - loss: 0.4220\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8642 - loss: 0.4010\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8812 - loss: 0.3338\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9267 - loss: 0.3003\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8835 - loss: 0.3008\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9221 - loss: 0.2742\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.8276 - loss: 0.3789\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8968 - loss: 0.3213\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8956 - loss: 0.2712\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9382 - loss: 0.2294\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9634 - loss: 0.2154\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9160 - loss: 0.2351\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9508 - loss: 0.2133\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9267 - loss: 0.2232\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9587 - loss: 0.2057\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9480 - loss: 0.1943\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.9169 - loss: 0.2312\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9209 - loss: 0.2269\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9042 - loss: 0.1913\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9344 - loss: 0.1710\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9511 - loss: 0.1450\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9434 - loss: 0.1400\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9244 - loss: 0.2045\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9315 - loss: 0.1656\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9232 - loss: 0.1600\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9312 - loss: 0.1540\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9395 - loss: 0.1710\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9544 - loss: 0.1324\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9787 - loss: 0.1296\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.9826 - loss: 0.1064\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9750 - loss: 0.1180\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9739 - loss: 0.0925\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9715 - loss: 0.1157\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9676 - loss: 0.0907\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.9851 - loss: 0.0730\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9555 - loss: 0.1006\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9863 - loss: 0.0808\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.0882 \n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9631 - loss: 0.0861\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9861 - loss: 0.0551\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9933 - loss: 0.0551\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9883 - loss: 0.0550\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9967 - loss: 0.0497\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 1.0000 - loss: 0.0581\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9892 - loss: 0.0554\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 1.0000 - loss: 0.0449\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9872 - loss: 0.0471\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9976 - loss: 0.0449\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9980 - loss: 0.0439\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 1.0000 - loss: 0.0608\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 1.0000 - loss: 0.0271\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 1.0000 - loss: 0.0370\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9976 - loss: 0.0275\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 1.0000 - loss: 0.0318\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 1.0000 - loss: 0.0340\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 1.0000 - loss: 0.0230\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 1.0000 - loss: 0.0196\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 1.0000 - loss: 0.0206\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0323\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 1.0000 - loss: 0.0144\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 1.0000 - loss: 0.0190\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 1.0000 - loss: 0.0120\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 1.0000 - loss: 0.0118\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 0.0117\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 0.0078\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 1.0000 - loss: 0.0049   \n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 0.0042\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 1.0000 - loss: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31b89c990>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(60,input_shape=(60,),activation='relu'),\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dense(15,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid'),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.9140 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8288494348526001, 0.7692307829856873]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[6.3009553e-09 9.3754703e-01 5.2833891e-01 4.5243578e-05 9.9999613e-01\n",
      " 9.9997455e-01 5.7933038e-01 9.9999613e-01 1.1785096e-04 9.9999869e-01]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186    0\n",
       "155    0\n",
       "165    0\n",
       "200    0\n",
       "58     1\n",
       "34     1\n",
       "151    0\n",
       "18     1\n",
       "202    0\n",
       "62     1\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        27\n",
      "           1       0.78      0.72      0.75        25\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.77      0.77      0.77        52\n",
      "weighted avg       0.77      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we add a dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.4763 - loss: 0.7397 \n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.5225 - loss: 0.6990\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.4516 - loss: 0.7134\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.4248 - loss: 0.7188\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.5477 - loss: 0.6915\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.5460 - loss: 0.6846\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.5347 - loss: 0.6927\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.4557 - loss: 0.7136\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.6473 - loss: 0.6765\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.4875 - loss: 0.6966\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.5110 - loss: 0.6981\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.6702 - loss: 0.6526\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.5364 - loss: 0.6824\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.5595 - loss: 0.6870\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.4937 - loss: 0.6927\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.5152 - loss: 0.6899\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.6159 - loss: 0.6467\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.6697 - loss: 0.6589\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.5898 - loss: 0.6627\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.5999 - loss: 0.6566\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.6115 - loss: 0.6536\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.5495 - loss: 0.6593\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5851 - loss: 0.6527\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.6574 - loss: 0.6361\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.6325 - loss: 0.6565\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.6851 - loss: 0.6065\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.7038 - loss: 0.5738\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.6055 - loss: 0.6556\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7452 - loss: 0.5935\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7156 - loss: 0.6081\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.6809 - loss: 0.6110\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.6633 - loss: 0.5987\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.7416 - loss: 0.5946\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7280 - loss: 0.5757\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.6920 - loss: 0.6059\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.6483 - loss: 0.5968\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.7797 - loss: 0.5567\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.7204 - loss: 0.5658\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8022 - loss: 0.4845\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.8240 - loss: 0.4998\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.6455 - loss: 0.6577\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7709 - loss: 0.4811\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7143 - loss: 0.4958\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.8078 - loss: 0.4650\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.7094 - loss: 0.5083\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8001 - loss: 0.4707\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7532 - loss: 0.5604\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.7714 - loss: 0.5107\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.7096 - loss: 0.5013\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.7885 - loss: 0.4687\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7805 - loss: 0.4453\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8363 - loss: 0.4350\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7940 - loss: 0.4131\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8189 - loss: 0.4368\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7496 - loss: 0.4559 \n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8371 - loss: 0.3785\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.8129 - loss: 0.4189\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8179 - loss: 0.4084\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7970 - loss: 0.4875\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7777 - loss: 0.4399\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.7989 - loss: 0.4705\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.8587 - loss: 0.4104\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8219 - loss: 0.4064\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.7827 - loss: 0.4268\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8125 - loss: 0.4059\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8442 - loss: 0.3681\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9174 - loss: 0.3705\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8947 - loss: 0.3707\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8399 - loss: 0.3613\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8606 - loss: 0.4107\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.8463 - loss: 0.4194\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.8643 - loss: 0.4217\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7945 - loss: 0.4521\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8447 - loss: 0.3911\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8385 - loss: 0.3975\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.8217 - loss: 0.4705\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8986 - loss: 0.2565\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8552 - loss: 0.3191\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.8724 - loss: 0.3531\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8635 - loss: 0.3627\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8979 - loss: 0.2961\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8580 - loss: 0.3363\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.8973 - loss: 0.2898\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8820 - loss: 0.3395\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.8305 - loss: 0.3617\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9113 - loss: 0.3018\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8893 - loss: 0.3228\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.8927 - loss: 0.3127\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.8770 - loss: 0.3235\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9242 - loss: 0.2629\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.8959 - loss: 0.2747\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9228 - loss: 0.2699\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9170 - loss: 0.3464\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8136 - loss: 0.3819\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9486 - loss: 0.2240\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.8945 - loss: 0.3177\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9229 - loss: 0.2585\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.8748 - loss: 0.3571\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8611 - loss: 0.2916\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x150306790>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modeld.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.9140 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8288494348526001, 0.7692307829856873]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "[6.8493560e-04 5.6112921e-01 8.4796798e-01 4.2321607e-02 9.9897528e-01\n",
      " 8.9642501e-01 3.4050274e-01 9.9935716e-01 4.8075099e-02 9.9928594e-01]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeld.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80        27\n",
      "           1       0.84      0.64      0.73        25\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.78      0.76      0.76        52\n",
      "weighted avg       0.78      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
